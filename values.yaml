# values.yaml
# ------------
airflow:
  image:
    repository: lotfinejad/airflow-pyspark
    tag: latest
    pullPolicy: IfNotPresent

  webserver:
    replicas: 1
    port: 8080

  scheduler:
    replicas: 1

  executor: KubernetesExecutor

  # Database connection
  database:
    host: airflow-postgresql
    port: 5432
    database: airflow
    username: airflow
    password: airflow
    # single URL to use everywhere
    url: "postgresql+psycopg2://airflow:airflow@airflow-postgresql:5432/airflow"

# PostgreSQL Configuration
postgresql:
  enabled: true
  image:
    repository: postgres
    tag: 13-alpine
    pullPolicy: IfNotPresent

  auth:
    username: airflow
    password: airflow
    database: airflow

  persistence:
    enabled: true
    size: 2Gi

# Service Configuration
service:
  type: NodePort
  port: 8080
  nodePort: 30080

# Persistent Volume Configuration
persistence:
  enabled: true
  storageClass: "standard"
  accessMode: ReadWriteOnce
  size: 5Gi

# Volume paths - using the mounted path in kind
volumes:
  hostPaths:
    dags:    /workspace/dags
    scripts: /workspace/scripts
    logs:    /workspace/logs
    plugins: /workspace/plugins

# Resource limits
resources:
  webserver:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
  scheduler:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "1000m"
  worker:
    requests:
      memory: "512Mi"
      cpu: "250m"
    limits:
      memory: "1Gi"
      cpu: "500m"

rbac:
  create: true

serviceAccount:
  create: true
  name: "airflow-worker"

kubernetes:
  namespace: "default"
  worker_container_repository: "lotfinejad/airflow-pyspark"
  worker_container_tag: "latest"
  delete_worker_pods: true
  delete_worker_pods_on_failure: false
  worker_pods_creation_batch_size: 1
  multi_namespace_mode: false
  worker_service_account_name: "airflow-worker"
