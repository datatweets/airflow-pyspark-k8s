---
# Source: airflow-pyspark/templates/airflow-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: airflow-config
  labels:
    app: airflow
    chart: airflow-pyspark-0.1.0
data:
  AIRFLOW__CORE__EXECUTOR: KubernetesExecutor
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgresql:5432/airflow
  AIRFLOW__CORE__LOAD_EXAMPLES: "False"
  AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "True"
  AIRFLOW__CORE__FERNET_KEY: "81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs="
  AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "True"
  AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth"
  JAVA_HOME: "/usr/lib/jvm/java-17-openjdk-arm64"
  SPARK_HOME: "/home/airflow/.local/lib/python3.8/site-packages/pyspark"
  # KubernetesExecutor specific configuration
  AIRFLOW__KUBERNETES__NAMESPACE: "default"
  AIRFLOW__KUBERNETES__WORKER_CONTAINER_REPOSITORY: lotfinejad/airflow-pyspark
  AIRFLOW__KUBERNETES__WORKER_CONTAINER_TAG: latest
  AIRFLOW__KUBERNETES__DELETE_WORKER_PODS: "True"
  AIRFLOW__KUBERNETES__WORKER_SERVICE_ACCOUNT_NAME: "airflow-worker"
---
# Source: airflow-pyspark/templates/postgresql-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgresql-pvc
  labels:
    app: postgresql
    chart: airflow-pyspark-0.1.0
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 2Gi
  storageClassName: standard
---
# Source: airflow-pyspark/templates/airflow-webserver-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: airflow-webserver
  labels:
    app: airflow-webserver
    component: webserver
    chart: airflow-pyspark-0.1.0
spec:
  type: NodePort
  ports:
  - port: 8080
    targetPort: 8080
    protocol: TCP
    name: webserver
    nodePort: 30080
  selector:
    app: airflow-webserver
    component: webserver
---
# Source: airflow-pyspark/templates/postgresql-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: airflow-postgresql
  labels:
    app: airflow-postgresql
    chart: airflow-pyspark-0.1.0
spec:
  type: ClusterIP
  ports:
  - port: 5432
    targetPort: 5432
    protocol: TCP
    name: postgresql
  selector:
    app: airflow-postgresql
---
# Source: airflow-pyspark/templates/airflow-configmap.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
spec:
  template:
    spec:
      serviceAccountName: airflow-scheduler
      containers:
      - name: airflow-scheduler
        envFrom:
        - configMapRef:
            name: airflow-config
---
# Source: airflow-pyspark/templates/airflow-scheduler-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-scheduler
  labels:
    app: airflow
    component: scheduler
    chart: airflow-pyspark-0.1.0
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow
      component: scheduler
  template:
    metadata:
      labels:
        app: airflow
        component: scheduler
    spec:
      serviceAccountName: airflow-scheduler
      initContainers:
      - name: wait-for-db-init
        image: "lotfinejad/airflow-pyspark:latest"
        imagePullPolicy: IfNotPresent
        command: 
        - /bin/bash
        - -c
        - |
          while ! nc -z airflow-postgresql 5432; do
            echo "Waiting for database initialization..."
            sleep 5
          done
          echo "Database is initialized!"
        envFrom:
        - configMapRef:
            name: airflow-config
      containers:
      - name: airflow-scheduler
        image: "lotfinejad/airflow-pyspark:latest"
        imagePullPolicy: IfNotPresent
        command: ["airflow", "scheduler"]
        envFrom:
        - configMapRef:
            name: airflow-config
        volumeMounts:
        - name: dags
          mountPath: /opt/airflow/dags
        - name: scripts
          mountPath: /opt/airflow/scripts
        - name: logs
          mountPath: /opt/airflow/logs
        - name: plugins
          mountPath: /opt/airflow/plugins
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
      volumes:
      - name: dags
        hostPath:
          path: /Users/lotfinejad/airflow-pyspark-k8s/dags
          type: Directory
      - name: scripts
        hostPath:
          path: /Users/lotfinejad/airflow-pyspark-k8s/scripts
          type: Directory
      - name: logs
        hostPath:
          path: /Users/lotfinejad/airflow-pyspark-k8s/logs
          type: Directory
      - name: plugins
        hostPath:
          path: /Users/lotfinejad/airflow-pyspark-k8s/plugins
          type: Directory
---
# Source: airflow-pyspark/templates/airflow-webserver-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-webserver
  labels:
    app: airflow-webserver
    component: webserver
    chart: airflow-pyspark-0.1.0
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-webserver
      component: webserver
  template:
    metadata:
      labels:
        app: airflow-webserver
        component: webserver
    spec:
      initContainers:
      - name: wait-for-postgres
        image: busybox:1.35
        command: 
        - sh
        - -c
        - |
          until nc -z airflow-postgresql 5432; do
            echo "Waiting for PostgreSQL..."
            sleep 2
          done
          echo "PostgreSQL is ready!"
      - name: wait-for-db-init
        image: "lotfinejad/airflow-pyspark:latest"
        command:
        - sh
        - -c
        - |
          until airflow db check; do
            echo "Waiting for database initialization..."
            sleep 5
          done
          echo "Database is initialized!"
        envFrom:
        - configMapRef:
            name: airflow-config
      containers:
      - name: airflow-webserver
        image: "lotfinejad/airflow-pyspark:latest"
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8080
          name: webserver
        command: ["airflow", "webserver"]
        envFrom:
        - configMapRef:
            name: airflow-config
        volumeMounts:
        - name: dags
          mountPath: /opt/airflow/dags
        - name: scripts
          mountPath: /opt/airflow/scripts
        - name: logs
          mountPath: /opt/airflow/logs
        - name: plugins
          mountPath: /opt/airflow/plugins
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 120
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 5
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 10
          timeoutSeconds: 10
          failureThreshold: 3
        resources:
          limits:
            cpu: 1000m
            memory: 2Gi
          requests:
            cpu: 500m
            memory: 1Gi
      volumes:
      - name: dags
        hostPath:
          path: /Users/lotfinejad/airflow-pyspark-k8s/dags
          type: DirectoryOrCreate
      - name: scripts
        hostPath:
          path: /Users/lotfinejad/airflow-pyspark-k8s/scripts
          type: DirectoryOrCreate
      - name: logs
        hostPath:
          path: /Users/lotfinejad/airflow-pyspark-k8s/logs
          type: DirectoryOrCreate
      - name: plugins
        hostPath:
          path: /Users/lotfinejad/airflow-pyspark-k8s/plugins
          type: DirectoryOrCreate
---
# Source: airflow-pyspark/templates/postgresql-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: airflow-postgresql
  labels:
    app: airflow-postgresql
    chart: airflow-pyspark-0.1.0
spec:
  replicas: 1
  selector:
    matchLabels:
      app: airflow-postgresql
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: airflow-postgresql
    spec:
      containers:
      - name: postgresql
        image: "postgres:13-alpine"
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 5432
          name: postgresql
        env:
        - name: POSTGRES_USER
          value: airflow
        - name: POSTGRES_PASSWORD
          value: airflow
        - name: POSTGRES_DB
          value: airflow
        - name: PGDATA
          value: /var/lib/postgresql/data/pgdata
        volumeMounts:
        - name: postgresql-storage
          mountPath: /var/lib/postgresql/data
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
      volumes:
      - name: postgresql-storage
        persistentVolumeClaim:
          claimName: postgresql-pvc
---
# Source: airflow-pyspark/templates/airflow-init-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: airflow-init-db-1
  labels:
    app: airflow-init
    chart: airflow-pyspark-0.1.0
spec:
  ttlSecondsAfterFinished: 300
  template:
    metadata:
      labels:
        app: airflow-init
    spec:
      restartPolicy: OnFailure
      initContainers:
      - name: wait-for-postgres
        image: busybox:1.35
        command: 
        - sh
        - -c
        - |
          until nc -z airflow-postgresql 5432; do
            echo "Waiting for PostgreSQL..."
            sleep 2
          done
          echo "PostgreSQL is ready!"
      containers:
      - name: airflow-init
        image: "lotfinejad/airflow-pyspark:latest"
        imagePullPolicy: IfNotPresent
        command: 
        - bash
        - -c
        - |
          airflow db migrate
          airflow users create \
            --username admin \
            --password admin \
            --firstname Admin \
            --lastname User \
            --role Admin \
            --email admin@example.com || true
        envFrom:
        - configMapRef:
            name: airflow-config
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
